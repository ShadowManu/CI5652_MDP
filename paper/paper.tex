\documentclass{ci5652}
\usepackage{graphicx,amssymb,amsmath}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{hyperref}
\usepackage{subfigure}
\usepackage{paralist}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{graphicx}
\usepackage[labelfont=bf,textfont=it,small]{caption}
\usepackage[section]{placeins}

\setlength{\parskip}{0.5em}

\graphicspath{ {./images/} }

%----------------------- Macros and Definitions --------------------------

% Add all additional macros here, do NOT include any additional files.

% The environments theorem (Theorem), invar (Invariant), lemma (Lemma),
% cor (Corollary), obs (Observation), conj (Conjecture), and prop
% (Proposition) are already defined in the ci5652.cls file.

%----------------------- Title -------------------------------------------

\title{Estudio de Aplicación de Metaheurísticas al \\ problema Maximum Diversity Problem (MDP)}

\author{Cristian Medina
        \and
        Manuel Pacheco}

%------------------------------ Text -------------------------------------

\begin{document}
\thispagestyle{empty}
\maketitle
\

\section{Introducción}
El presente artículo presenta un estudio sencillo de la aplicación de metaheurísticas para la resolución del problema de diversidad máxima(Maximun Diversity Problem, MDP). Se realiza un estudio comparativo de las técnicas de Local Search (LS), Iterated Local Search (ILS), Tabu Search (TS), Genetic Algorithm (GA) y Scatter Search (SS) en las intancias del problema en los sets SOM, GKD y MDG de MDPLIB de optsicom.es. Se le dedica a cada metaheurística una sección con su descripción y pseudocódigo correspondiente.

El estudio de nuevas formas de solucionar este problema, así como identificar aquellas técnicas que puedan dar indicios a nuevas investigaciones en el área son de importancia, dada las aplicaciones que tienen las soluciones a la ingenieŕia génetica, el diseño de sistemas ecológicos, controles de inmigración, tratamientos médicos, inversión de capital, entre otros. 

\section{Modelación}
El problema de máxima diversidad (Maximum Diversity Problem), consiste en elegir M elementos de un conjunto de N elementos tal que las suma de las distancias entre los elementos elegidos sea la máxima posible. Catalogado como un problema NP-Hard en 1993 por Kou, Glover y Dhit, el problema está formalmente estipulado bajo la siguiente fórmulas de función objetivo a maximizar y restricción de tamaño:

$$\sum_{i=1}^{n-1} \sum_{j=i+1}^n d_{ij}x_ix_j$$
$$\sum_{i=1}^{n}x_i<m$$ 
Donde $n$ es la cardinalidad de elementos del conjunto, $m$ la cantidad de elementos elegidos, $d_{ij}$ es la distancia entre el elemento $i$ y el elemento $j$, $x_i$ es una función booleana que toma el valor de 1 si el elemento $i$ fue elegido, 0 si no fue elegido. Estas definiciones son las utilizadas en menciones posteriores en caso de omitirse una definición en el momento. Fue catalogado como un problema NP-Hard en 1993 por Kou, Glover y Dhit al reducir el problema de clique a MDP.

\section{Trabajos Previos}
El problema de máxima diversidad ha sido estudiado aplicando múltiples heurísticas y metahaurísticas. En general todas las heurísticas estudiadas presentan buenos resultados, sin embargo, se destacan las de búsqueda local al poseer resultados de mejor calidad para la mayor parte de los casos de prueba.

Se destaca en particular el Basic VNS por Brimberg~\cite{vnsbrimberg}. Este consiste en una estructura de datos eficiente que representa los conjuntos de datos actualizados, del cual genera aleatoriamente una solución parcial a la cual le aplica una búsqueda local intercambiando los elementos de su solución con los elementos no incluidos.
En un segundo lugar, se encuentra el VNS implementado por Aringhieri y Cordone~\cite{vnsarincor}, el cual consiste en una construcción de una solución con un método greedy y un posterior procesamiento cambiando k elementos de la solución y aplicando una búsqueda tabú simple sobre esta.

Para casos de prueba de mayor tamaño, se destaca las búsquedas en Tabú. Un ejemplo de esta es la presentada por Palubeckis~\cite{palubeckis}, una búsqueda Tabú iterativa que alterna entre búsqueda tabú y técnicas de perturbación. Cuando la búsqueda Tabú encuentra un resultado mejor al inicial, utiliza una búsqueda local a la nueva solución. Su método de perturbación es una selección de elementos aleatorios del conjunto para viajar por el espacio de soluciones. Para casos pequeños este método se desempeña bien, pero no es el mejor.

Cabe destacar también los estrategias GRASP desarrolladas por Silva et~\cite{silva}, donde se construye una solución parcial inicial y se mejora de forma iterativa; y la propuesta por Duarte y Martí~\cite{duarmar}, que parten de la heurística propuesta por Glover de C2 y D2, aplicándole su propia metodología GRASP.

\section{Representación de la solución}
Para la representación de una solución del problema se utilizan dos alternativas. Para los algoritmos LS, ILS, TS y SS se optó por una representación compacta.
Sea el conjunto de elementos de tamaño $n$ y la solución de tamaño $m$, se opta por representar la solución como un vector de tamaño $m$ donde cada componente contiene la etiqueta del elemento escogido. Para GA se utiliza una representación completa: un vector de tamaño $n$ donde cada componente está permanentemente asociada a un elemento del problema e indica si pertenece o no a la solución (i.e. un $x_i$ como en la descripción del problema).

\section{Solución Inicial}
Dependiendo de la metaheurística a utilizar se usan métodos de construcción de las soluciones iniciales de forma diferente. La primera es la clásica solución aleatoria: se seleccionan los elementos que pertenecen a la solución al azar. La segunda sigue un principio de intuición que denominamos $Potencial$ de un elemento definida de la siguiente forma:

$$P(i)=\sum_{j=1}^{n}d_{ij}$$

De manera informal, el $Potencial$ de un elemento indica cuánto aporta a la función objetivo si se tomasen en cuenta todas las conexiones con todos los demás elementos. Por tanto, elegimos los primeros $m$ nodos que tengan mayor potencial. Definimos a esta estrategia como solución inicial greedy.

En la mayoría de los problemas trabajados, las soluciones aleatorias rondan generalmente entre 50\% y 75\% del valor de las mejores soluciones encontradas en la librería (soluciones referencia), dependiendo del tamaño del problema, siendo las peores las de problemas más grandes. La solución greedy supera el 95\% y tiende a llegar tan alto como 98\% de la solución referencia.

En la mayoría de los problemas se intenta utilizar la solución greedy sobre la aleatoria. Para LS, ILS y TS se utiliza greedy. Para las metaheurísticas poblacionales GA y SS, se inicia con soluciones aleatorias.

\section{Local Search (LS)}
El primer algoritmo implementado consiste en Búsqueda Local. Durante la búsqueda, el objetivo es mejorar una solución existente modificando aquellos elementos que lleven la solución a acercarse a un óptimo (al menos de forma local).

La implementación de LS esta basada en el uso de $k\text{--}opt$, con 4 características en las cuales hacer énfasis:
\begin{itemize} \itemsep5pt
	\item Se busca mejorar los $m$ componentes de la solución.
	\item Los vecinos de cada componente son definidos en base al tamaño $n$ del problema.
	\item Cada componente es reemplazada por el mejor candidato encontrado
	\item La búsqueda por componente se detiene si ha pasado un numero de iteraciones sin conseguir una solución candidata que mejore la solución actual.
\end{itemize}

\subsection{Algoritmo de Local Search}
El algoritmo utilizado es equivalente al aquí mostrado, abstrayendo las particularidades de implementación y optimización del algoritmo. Esto aplica a todos los algoritmos mostrados en el presente documento.

\begin{algorithm}[h!]
\DontPrintSemicolon
$S \leftarrow$ Solucion del problema\;
$S_i \leftarrow$ elemento $i$ de la solucion\;
$U \leftarrow$ elementos no escogidos\;
$P \leftarrow$ elementos del problema\;
\Begin{
	$S \leftarrow$ SolucionInicial()\;
	\ForEach{$i \in |S|$ de derecha a izquierda}{
		$U' \leftarrow$ NH\_SIZE elementos aleatorios de U\;
		\ForEach{$u \in U'$}{
			$S' \leftarrow$ S con $S_i$ reemplazado por u\;
			\If{$valor(S') > valor(S)$}{
				$S \leftarrow S'$\;
			}
			\If{pasan MAX\_REPEATS iteraciones sin cambiar $S$}{
				break\;
			}
		}			
	}	
}
\end{algorithm}

Para NH\_SIZE y MAX\_REPEATS se entonaron los valores de $\frac{|P|-|S|}{5}$ y $30$ respectivamente.

\subsection{Resultados de Local Search}
La aplicación de LS a una solución dada, en general logra mejorar la solución y acercarla hacia el óptimo (en general, local). Quizá uno de los resultados más importantes en una revisión individual de LS, es cómo se comporta con diferentes soluciones. En la figura ~\ref{fig:localsearch-solution-randomgreedy}, se hacen 15 pruebas sobre 5 problemas del set mediano iniciando con una solución aleatoria (r) y una solución greedy (g).
El comportamiento observado es el esperado: local search mejora localmente una solución dada; con una solución greedy se obtienen mejores resultados pero sucesivas aplicaciones de LS a una solución arbitraria podrían igualmente obtenerlos.

\begin{figure*}[]
	\setlength\fboxsep{0pt}
	\setlength\fboxrule{0.5pt}
	\fbox{\includegraphics[width=\textwidth]{localsearch-solution-randomgreedy}}
	\caption{Comparación de soluciones de LS utilizando soluciones random y greedy en problemas de tamaño mediano.}
	\label{fig:localsearch-solution-randomgreedy}
\end{figure*}

\section{Iterated Local Search (ILS)}
En la búsqueda ILS, se intenta resolver el problema principal que aqueja a la búsqueda local: puede quedarse estancado en soluciones óptimas locales, sin llegar al óptimo global. Esto puede resolverse aplicando búsqueda local sobre diferentes soluciones iniciales, mas conservando de cierta forma aquello que las búsquedas anteriores pudieran aportar para hallar la solución óptima.

\subsection{Operador de perturbación de ILS}
Para cambiar las soluciones, realizamos una perturbación en base a un tamaño $k$, en la que se eligen $k$ elementos escogidos en la solución y se reemplazan con elementos no escogidos en la solución actual.

\subsection{Condiciones de control de ILS}
En la implementación existen 3 condiciones que controlan la forma en que se realizan las búsquedas:
\begin{itemize} \itemsep5pt
	\item Intentos de $k$: cuantas busquedas con el mismo tamaño $k$ se permiten sin mejora antes de incrementarlo.
	\item Incremento de $k$: en cuanto se incrementa el tamaño de la perturbación y el límite de este incremento.
	\item Máximo de Iteraciones: cuantas iteraciones totales se permiten realizar durante la ejecución completa del algoritmo.
\end{itemize}

\subsection{Algoritmo de ILS}
\begin{algorithm}[h!]
\DontPrintSemicolon
$S \leftarrow$ Solucion del problema\;
$k \leftarrow$ tamaño de la perturbacion\;
\Begin{
	$S \leftarrow$ SolucionInicial()\;
	$k \leftarrow INIT\_SIZE$\;
	$k\_tries \leftarrow 0$\;
	\For{$i = 1 \to$ MAX\_ITERATIONS}{
		$S' \leftarrow$ shake($S$,$k$)\;
		$S'' \leftarrow$ localSearch($S'$)\;
		\If{value($S''$) $>$ value($S$))}{
			$S \leftarrow S''$\;
			$k \leftarrow INIT\_SIZE$\;
			$continue$\;
		}
		increment $k\_tries$\;
		\If{$k\_tries > MAX\_K\_TRIES$}{
			increment $k$\;
			$k\_tries \leftarrow 0$\;
			$continue$\;
		}
		\If{$k > |S|$}{
			$break$\;
		}
	}	
}
\end{algorithm}

\section{Tabu Search}
La versión del algoritmo Tabu Search implementado es sencillo. Consiste en, a partir de una solución inicial aleatoria, cambiar el 10\% de los nodos de la solución aleatoriamente por nodos no elegidos por la solución que tampoco sean tabu, sin criterio de aspiración para los elementos tabu. Si estos cambios mejoran la solución, los intercambios de nodos realizados son marcados como tabu por 30 iteraciones, y mejor solución es actualizada~\cite{fgtabu}.

\subsection{Algoritmo Tabu}
\begin{algorithm}[h!]
\DontPrintSemicolon
$Bs\leftarrow$ Mejor Solución\;
$S \leftarrow$ Solucion inicial Aleatoria\;
$k \leftarrow$ |S|*0.1\;
$JailTime \leftarrow$ 30 //Tiempo de combinaciones siendo Tabu\;
$TabuList[|Nodes|][|Nodes|] \leftarrow$ Matriz de Booleanos de Cambios inicializado todas las casillas en Verdadero\;
$Q \leftarrow \emptyset$ //Cola de pares combinaciones a liberar\;
\Begin{
	$Bs \leftarrow S$\;
	\For{$i = 1 \to  MAX\_ITERATION$}{
		$D \leftarrow$ k nodos aleatorios en S\;
		$T \leftarrow$ k nodos aleatorios fuera de S\;
		\For{$j=0 \to k$}{
			\If{$TabuList[D[j]][T[j]]$}{
				$TabuList[D[j]][T[j]] \leftarrow Falso$\;
				Q.push((D[j],T[j]))\;
				$S \leftarrow (S - D[j]) \cup T[j]$\;
			}
			\Else {
				$T[k] \leftarrow$ nodo aleatorio fuera de S\;
				$j \leftarrow j-1$\;
			}
		}
		
		\If{fitness($S$) $>$ fitness($Bs$)}{
			$Bs \leftarrow S$\;
		}
		
		\If{$i > JailTime$)}{
			\For{$l=0 \to k$}{
				$TabuList[Q.top().first][Q.top().second] \leftarrow Verdadero$\;
				Q.pop()\;
			}
		}
	}
}
\end{algorithm}

\section{Genetic Algorithm (GA)}
El algoritmo genético consiste en una simulación genética de las soluciones, donde se posee una población donde cada individuo representa una instancia de solución y se aplican simulaciones de selección, cruce y mutación genéticas a modo de imitación del proceso natural de los seres vivos. Se implementó un algoritmo genético generacional para la resolución de este problema: las nuevas poblaciones reemplazan a las anteriores, manteniendo el mismo tamaño en la población durante todo el algoritmo.

\subsection{Representacion del Cromosoma de GA}
Dada las características del problema, la representación utilizada en las demás metaheurísticas era poco útil/eficiente para la implementación de un operador de cruce en GA. En esta metaheurística, se utiliza la representación completa, descrita en la sección \textit{"Representación de la solución"}.

\subsection{Población Inicial}
Se utiliza una población inicial de tamaño fijo y cada elemento es construido de forma aleatoria.

\subsection{Operador de Selección de GA}
Para la selección de los individuos a ser utilizados en el cruce, se utilizó roulette-wheel sampling con elitismo simple: se seleccionan individuos al azar con tendencia a los individuos con mejor "fitness". El fitness es directamente proporcional al valor de la función objetivo. Con respecto al elitismo simple, no se permite elegir al mejor individuo de la población.

\subsection{Operador de Cruce de GA}
Dadas las características del problema El operador de cruce implementado es un operador personalizado, de 2 padres a 2 hijos, descrito informalmente de la siguiente forma: \textit{en las componentes en que los padres coinciden, los hijos coinciden. En las componentes que solo 1 padre lo posee, se reparten alternativamente entre los 2 hijos}. Adicionalmente, se tiene la condición de que los hijos reemplazan a sus padres si poseen mejor fitness.

\subsection{Operador de Mutación de GA}
Utilizamos un operador de mutación bastante simple y débil: se intercambia un elemento presente en la solución por uno que no este presente en la solución. Sin embargo, la mutación se usa con una muy alta probabilidad: al final de cada generación, 1 de cada MUTATION\_SIZE elementos (seleccionados al azar) son mutados. Esta alta probabilidad de mutación resultó en mejores resultados para GA en los problemas medianos.

\subsection{Algoritmo de GA}
\begin{algorithm}[h!]
\DontPrintSemicolon
$P \leftarrow$ Poblacion de invididuos\;
$C \leftarrow$ Individuos Elegidos\;
$S_i \leftarrow$ Solucion $i$ de un conjunto de soluciones\;
\Begin{
	$P \leftarrow$ PoblacionInicial(POP\_SIZE)\;
	\For{$i = 1 \to $ N\_GENERATIONS}{
		$C \leftarrow$ Seleccion(P)\;
		\ForEach{$S_i,S_{i+1} \in C$}{
			$S'_i,S'_{i+1} \leftarrow$ Cruce($S_i,S_{i+1}$)\;
			\If{fitness($S'_i$) $>$ fitness($S_i$)}{
				replace($S'_i$,$S_i$,P)\;
			}
			\If{fitness($S'_i+1$) $>$ fitness($S_i+1$)}{
				replace($S'_{i+1}$,$S_{i+1}$,P)\;
			}
		}
		Mutacion(P,MUTATION\_SIZE);
	}
}
\end{algorithm}

Para los valores de POP\_SIZE, N\_GENERATIONS y MAX\_REPEATS se entonaron los valores de $100$, $200$ y $4$ respectivamente.

\section{Scatter Search}
Se realizó una implementación de Scatter Search con una población P de tamaño 100, y un conjunto de referencia de tamaño constante 10. Se realizan 5 ciclos del SS, que consiste en generar una población P, obtener el conjunto de referencia y comenzar un ciclo interno donde se combinan las soluciones del conjunto de referencia, se mejoran las soluciones, y se actualiza el conjunto de referencia, hasta que no se realicen cambios en una de las iteraciones, por lo que se guarda la mejor solución y se procede a la siguiente iteración~\cite{ssmarti}.

\subsection{Conjunto de Referencia de SS}
Tomando una población inicial P de tamaño 100 con soluciones aleatorias y mejorando las soluciones con un Local Search, el conjunto de referencia consta, incialmente, de las 5 mejores soluciones de esta población P, y 5 soluciones más diferentes para cada una de las primeras 5 mencionadas, ordenadas las soluciones de mejor a peor.

\subsection{Combinaciones de SS}
Las combinaciones son entre 2 soluciones, combinando las primeras 5 soluciones del conjunto con las otras 5 restantes. Las combinaciones consisten en tomar aleatoriamente elementos suficientes de entre las dos soluciones para generar una nueva, con un mejoramiento posterior usando Local Search.

\subsection{Actualización del Conjunto de Referencia de SS}
Si una solución generada en las combinaciones es mejor que alguna de las soluciones del conjunto de referencia, se introduce al conjunto, eliminando la peor solución del conjunto para mantener el tamaño, asegurando que se mantenga el orden de mejor a peor slución.

\subsection{Algoritmo de SS}

\begin{algorithm}[h!]
\DontPrintSemicolon
$S \leftarrow$ Mejor solución obtenida\;
\Begin{
	\For{$i = 1 \to $ 5}{
		$P \leftarrow$ Poblacion Inicial Aleatoria\;
		Improvement(\textit{P})\;
		$refSet \leftarrow$ 5 mejores Soluciones de P\;
		
		\ForEach{$p \in P \wedge r \in refSet$}{
			$refSet \leftarrow refSet\cup$ Max(Diferencia(r,p))\;
		}
			
		\For{Cambia}{
			$Cambia \leftarrow$ falso\;
			$C \leftarrow$ combinaciones a partir de refSet\;
			\ForEach{$c \in C$}{
				Improvement(c)\;
				\ForEach{$r \in refSet$}{
					\If{fitness($c$) $>$ fitness($r$)}{
					
						$refSet \leftarrow refSet\cup c$\;
						$refSet \leftarrow refSet$ - Peor(refSet)\;
						$Cambia \leftarrow$ verdadero\;
					}
				}
			}		
		}
		
		\If{fitness($MejorSolucion(refSet)$) $>$ fitness($S$)}{
			$S \leftarrow$ MejorSolucion(refSet)\;
		}
	}
}
\end{algorithm}

\section{Resultados}

\subsection{Computador de Pruebas}
Las pruebas fueron realizas bajo un equipo con las siguientes propiedades:
\begin{itemize} \itemsep0pt
	\item Sistema Operativo: Ubuntu 15.04 de 64 bits.
	\item Kernel de SO: 3.19.0-21
	\item Procesador: Intel Core i7-4700MQ
	\item RAM: 8 GB RAM DDR3
\end{itemize}

\subsection{Casos de Prueba}
Para las pruebas se utilizaron los casos de prueba de la librería MDPLIB:
\begin{itemize}
	\item SOM-b: 5 problemas de $n$ entre 100 y 200 y $m$ entre 10 y 40.
	\item GKD-c: 20 problemas de $n$ 500 y $m$ 50.
	\item MDG-b/c: 5 problemas de $n$ entre 2000 y 300 y $m$ entre 200 y 600.
\end{itemize}

%---------------------------- Bibliography -------------------------------

% Please add the contents of the .bbl file that you generate,  or add bibitem entries manually if you like.
% The entries should be in alphabetical order
\small
\bibliographystyle{abbrv}

\begin{thebibliography}{99}

\bibitem{vnsbrimberg}
Brimberg, J., N. Mladenovic, D. Urosevic and E. Ngai. (2009).
\newblock Variable neighborhood search for the heaviest k-subgraph.
\newblock {\em Computers $\&$ Operations Research}, 36(11): 2885-2891.

\bibitem{vnsarincor}
R. Aringhieri and R. Cordone.
\newblock Better and faster solutions for the maximum diversity problem.
\newblock {\em Technical report, Universit degli Studi di Milano, Polo Didattico e di Ricerca di Crema}, 2006.

\bibitem{silva}
G.C. Silva, M.R.Q. Andrade, L.S. Ochi, S.L. Martins, and A. Plastino.
\newblock New heuristics for the maximum diversity problem.
\newblock {\em Journal of Heuristics}, 13(4):315–336, 2007.

\bibitem{duarmar}
R. Aringhieri, R. Cordone, and Y. Melzani.
\newblock Tabu search vs. grasp for the maximum diversity problem.
\newblock {\em A Quarterly Journal of Operations Research}, 6(1):45–60, 2008.

\bibitem{palubeckis}
G. Palubeckis.
\newblock Iterated tabu search for the maximum diversity problem.
\newblock {\em Applied Mathematics and Computation}, 189:371383, 2007.

\bibitem{ssmarti}
R. Martí, M. Laguna.
\newblock Tabu Search.
\newblock {\em Departamento de Estadística e Investigación Operativa,
Universitat de València}.

\bibitem{fgtabu}
F. Glover, B. Melián.
\newblock Scatter Search: Diseño Básico y Estrategias Avanzadas.
\newblock {\em Inteligencia Artificial, Revista Iberoamericana de Inteligencia Artificial. No.19}, 2003, pp. 29-48.


\end{thebibliography}

\end{document}
